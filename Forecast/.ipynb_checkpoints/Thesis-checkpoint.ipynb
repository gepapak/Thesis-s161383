{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uV1d37Icaurl",
        "outputId": "95838b7c-ace4-466e-c1b3-6997c0ee72be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ewtpy in /usr/local/lib/python3.11/dist-packages (0.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.19.0)\n",
            "Requirement already satisfied: tensorflow-docs in /usr/local/lib/python3.11/dist-packages (2025.2.19.33219)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from ewtpy) (1.14.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.5.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: astor in /usr/local/lib/python3.11/dist-packages (from tensorflow-docs) (0.8.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from tensorflow-docs) (3.1.6)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.11/dist-packages (from tensorflow-docs) (5.10.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from tensorflow-docs) (6.0.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->tensorflow-docs) (3.0.2)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat->tensorflow-docs) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat->tensorflow-docs) (4.23.0)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.11/dist-packages (from nbformat->tensorflow-docs) (5.7.2)\n",
            "Requirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.11/dist-packages (from nbformat->tensorflow-docs) (5.7.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->tensorflow-docs) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->tensorflow-docs) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->tensorflow-docs) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->tensorflow-docs) (0.24.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat->tensorflow-docs) (4.3.7)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install ewtpy tensorflow tensorflow-docs scikit-learn pandas numpy matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ns5jBMQglu7j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfad4f1f-2857-4e3d-871f-8bc58d1cfd40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.19.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.5.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JJgw81d0kf9M"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import ewtpy\n",
        "\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn import metrics\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from math import sqrt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version\n",
        "!pip list | grep PyEMD\n"
      ],
      "metadata": {
        "id": "DyGZHIBbtupJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cac2877e-af2d-40f4-d731-311797623742"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.11.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xmdetdwMEFx7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8bc730f-36fa-42df-cbb0-3a3740c2d478"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path = \"/content/drive/My Drive/datasets/haute.csv\"\n",
        "df = pd.read_csv(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9GCBV5B5E9Zv"
      },
      "outputs": [],
      "source": [
        "#convert an array of values into a dataset matrix\n",
        "def create_dataset(dataset, look_back=1):\n",
        "    dataX, dataY = [], []\n",
        "    for i in range(len(dataset)-look_back-1):\n",
        "        a = dataset[i:(i+look_back), 0]\n",
        "        dataX.append(a)\n",
        "        dataY.append(dataset[i + look_back, 0])\n",
        "    return np.array(dataX), np.array(dataY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "3JpU03Pses5Y"
      },
      "outputs": [],
      "source": [
        "# SVR Model Function\n",
        "def svr_model(new_data, i, look_back, data_partition, cap):\n",
        "    x = i\n",
        "    data1 = new_data.loc[new_data['Month'].isin(x)]\n",
        "    data1 = data1.reset_index(drop=True).dropna()\n",
        "    datas = data1['P_avg']\n",
        "    datas_wind = pd.DataFrame(datas)\n",
        "    dfs = datas\n",
        "    s = dfs.values\n",
        "\n",
        "    datasetss2 = pd.DataFrame(s)\n",
        "    datasets = datasetss2.values\n",
        "\n",
        "    train_size = int(len(datasets) * data_partition)\n",
        "    test_size = len(datasets) - train_size\n",
        "    train, test = datasets[0:train_size], datasets[train_size:len(datasets)]\n",
        "\n",
        "    trainX, trainY = create_dataset(train, look_back)\n",
        "    testX, testY = create_dataset(test, look_back)\n",
        "    X_train = pd.DataFrame(trainX)\n",
        "    Y_train = pd.DataFrame(trainY)\n",
        "    X_test = pd.DataFrame(testX)\n",
        "    Y_test = pd.DataFrame(testY)\n",
        "\n",
        "    sc_X = StandardScaler()\n",
        "    sc_y = StandardScaler()\n",
        "\n",
        "    X = sc_X.fit_transform(X_train)\n",
        "    y = sc_y.fit_transform(Y_train).ravel()\n",
        "    X1 = sc_X.transform(X_test)\n",
        "    y1 = sc_y.transform(Y_test).ravel()\n",
        "\n",
        "    # Set random seed for reproducibility\n",
        "    np.random.seed(1234)\n",
        "    tf.random.set_seed(1234)\n",
        "\n",
        "    grid = SVR(kernel='rbf')\n",
        "    grid.fit(X, y)\n",
        "\n",
        "    y_pred_train_svr = grid.predict(X)\n",
        "    y_pred_test_svr = grid.predict(X1)\n",
        "\n",
        "    # Inverse transform predictions\n",
        "    y_pred_train_svr = sc_y.inverse_transform(y_pred_train_svr.reshape(-1, 1))\n",
        "    y_pred_test_svr = sc_y.inverse_transform(y_pred_test_svr.reshape(-1, 1))\n",
        "\n",
        "    y_train = sc_y.inverse_transform(y.reshape(-1, 1))\n",
        "    y_test = sc_y.inverse_transform(y1.reshape(-1, 1))\n",
        "\n",
        "    # Convert to DataFrame if needed\n",
        "    y_pred_train_svr = pd.DataFrame(y_pred_train_svr)\n",
        "    y_pred_test_svr = pd.DataFrame(y_pred_test_svr)\n",
        "    y_test = pd.DataFrame(y_test)\n",
        "\n",
        "    # Summarize the fit of the model\n",
        "    mape = np.mean((np.abs(y_test - y_pred_test_svr)) / cap) * 100\n",
        "    rmse = sqrt(mean_squared_error(y_test, y_pred_test_svr))\n",
        "    mae = metrics.mean_absolute_error(y_test, y_pred_test_svr)\n",
        "\n",
        "    print('MAPE:', mape)\n",
        "    print('RMSE:', rmse)\n",
        "    print('MAE:', mae)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "5s81wH7ffWI0"
      },
      "outputs": [],
      "source": [
        "# ANN Model Function\n",
        "def ann_model(new_data, i, look_back, data_partition, cap):\n",
        "    data1 = new_data.loc[new_data['Month'].isin(i)].reset_index(drop=True).dropna()\n",
        "    datas = data1['P_avg']\n",
        "    datasets = datas.values.reshape(-1, 1)\n",
        "\n",
        "    train_size = int(len(datasets) * data_partition)\n",
        "    train, test = datasets[:train_size], datasets[train_size:]\n",
        "\n",
        "    trainX, trainY = create_dataset(train, look_back)\n",
        "    testX, testY = create_dataset(test, look_back)\n",
        "\n",
        "    sc_X = StandardScaler()\n",
        "    sc_y = StandardScaler()\n",
        "\n",
        "    X_train = sc_X.fit_transform(trainX)\n",
        "    y_train = sc_y.fit_transform(trainY.reshape(-1, 1)).ravel()\n",
        "    X_test = sc_X.transform(testX)\n",
        "    y_test = sc_y.transform(testY.reshape(-1, 1)).ravel()\n",
        "\n",
        "    # Ensure data is float32 for TensorFlow\n",
        "    X_train = np.array(X_train, dtype=np.float32)\n",
        "    y_train = np.array(y_train, dtype=np.float32)\n",
        "    X_test = np.array(X_test, dtype=np.float32)\n",
        "    y_test = np.array(y_test, dtype=np.float32)\n",
        "\n",
        "    # ✅ Keep 2D shape (no extra dimension)\n",
        "    trainX1 = X_train\n",
        "    testX1 = X_test\n",
        "\n",
        "    # Set random seed for reproducibility\n",
        "    np.random.seed(1234)\n",
        "    tf.random.set_seed(1234)\n",
        "    os.environ['PYTHONHASHSEED'] = '0'\n",
        "    tf.config.experimental.enable_op_determinism()\n",
        "\n",
        "    # ✅ Correct Input Shape for ANN\n",
        "    neuron = 128\n",
        "    model = Sequential()\n",
        "    model.add(Dense(units=neuron, activation='relu', input_shape=(trainX1.shape[1],)))  # Fixed input shape\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam())\n",
        "    model.fit(trainX1, y_train, verbose=0)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred_train = model.predict(trainX1)\n",
        "    y_pred_test = model.predict(testX1).ravel()\n",
        "\n",
        "    # Inverse transform predictions\n",
        "    y_pred_test = sc_y.inverse_transform(y_pred_test.reshape(-1, 1))\n",
        "    y_test = sc_y.inverse_transform(y_test.reshape(-1, 1))\n",
        "\n",
        "    # Summarize the fit of the model\n",
        "    mape = np.mean((np.abs(y_test - y_pred_test)) / cap) * 100\n",
        "    rmse = sqrt(mean_squared_error(y_test, y_pred_test))\n",
        "    mae = mean_absolute_error(y_test, y_pred_test)\n",
        "\n",
        "    print('MAPE:', mape)\n",
        "    print('RMSE:', rmse)\n",
        "    print('MAE:', mae)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "WdBKugsfq028"
      },
      "outputs": [],
      "source": [
        "# RF Model Function\n",
        "def rf_model(new_data, i, look_back, data_partition, cap):\n",
        "    data1 = new_data.loc[new_data['Month'].isin(i)].reset_index(drop=True).dropna()\n",
        "    datas = data1['P_avg']\n",
        "    datasets = datas.values.reshape(-1, 1)\n",
        "\n",
        "    train_size = int(len(datasets) * data_partition)\n",
        "    train, test = datasets[:train_size], datasets[train_size:]\n",
        "\n",
        "    trainX, trainY = create_dataset(train, look_back)\n",
        "    testX, testY = create_dataset(test, look_back)\n",
        "\n",
        "    sc_X = StandardScaler()\n",
        "    sc_y = StandardScaler()\n",
        "\n",
        "    X_train = sc_X.fit_transform(trainX)\n",
        "    y_train = sc_y.fit_transform(trainY.reshape(-1, 1)).ravel()\n",
        "    X_test = sc_X.transform(testX)  # Ensure only transform() is applied\n",
        "    y_test = sc_y.transform(testY.reshape(-1, 1)).ravel()\n",
        "\n",
        "    # Ensure data is float32 for TensorFlow\n",
        "    X_train = np.array(X_train, dtype=np.float32)\n",
        "    y_train = np.array(y_train, dtype=np.float32)\n",
        "    X_test = np.array(X_test, dtype=np.float32)\n",
        "    y_test = np.array(y_test, dtype=np.float32)\n",
        "\n",
        "    # Set random seed for reproducibility\n",
        "    np.random.seed(1234)\n",
        "    tf.random.set_seed(1234)\n",
        "    os.environ['PYTHONHASHSEED'] = '0'\n",
        "\n",
        "    # Define the RF model\n",
        "    grid = RandomForestRegressor()\n",
        "    grid.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred_train_rf = grid.predict(X_train)\n",
        "    y_pred_test_rf = grid.predict(X_test)\n",
        "\n",
        "    # Inverse transform predictions\n",
        "    y_pred_test_rf = sc_y.inverse_transform(y_pred_test_rf.reshape(-1, 1))\n",
        "    y_test = sc_y.inverse_transform(y_test.reshape(-1, 1))\n",
        "\n",
        "    # Summarize the fit of the model\n",
        "    mape = np.mean((np.abs(y_test - y_pred_test_rf)) / cap) * 100\n",
        "    rmse = sqrt(mean_squared_error(y_test, y_pred_test_rf))\n",
        "    mae = mean_absolute_error(y_test, y_pred_test_rf)\n",
        "\n",
        "    print('MAPE:', mape)\n",
        "    print('RMSE:', rmse)\n",
        "    print('MAE:', mae)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "9a1WlVjsEhXL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "e52989a3-0d0d-468f-d93d-11f534d17d1e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Wind_turbine_name        Date_time  Ba_avg  Ba_min  Ba_max  Ba_std  \\\n",
              "0                R80711    1/1/2017 0:00   -0.99   -0.99   -0.90    0.00   \n",
              "1                R80711    1/1/2017 0:10   -0.99   -0.99   -0.99    0.00   \n",
              "2                R80711    1/1/2017 0:20   -0.99   -0.99   -0.70    0.01   \n",
              "3                R80711    1/1/2017 0:30   -0.99   -0.99   -0.99    0.00   \n",
              "4                R80711    1/1/2017 0:40   -0.99   -0.99   -0.99    0.00   \n",
              "...                 ...              ...     ...     ...     ...     ...   \n",
              "53842            R80711  1/12/2018 23:20   -0.83   -0.99    0.00    0.32   \n",
              "53843            R80711  1/12/2018 23:30   -0.15   -0.49    0.23    0.23   \n",
              "53844            R80711  1/12/2018 23:40    0.03   -0.49    0.50    0.26   \n",
              "53845            R80711  1/12/2018 23:50    0.48    0.00    0.50    0.10   \n",
              "53846            R80711   1/13/2018 0:00   -0.06   -0.49    0.50    0.36   \n",
              "\n",
              "       Rt_avg  Rt_min  Rt_max  Rt_std  ...  Pas_max  Pas_std  Wa_c_avg  \\\n",
              "0       12.00    12.0   12.00    0.00  ...      NaN      NaN       NaN   \n",
              "1       12.00    12.0   12.00    0.00  ...      NaN      NaN       NaN   \n",
              "2       12.00    12.0   12.00    0.00  ...      NaN      NaN       NaN   \n",
              "3       12.00    12.0   12.00    0.00  ...      NaN      NaN       NaN   \n",
              "4       12.00    12.0   12.00    0.00  ...      NaN      NaN       NaN   \n",
              "...       ...     ...     ...     ...  ...      ...      ...       ...   \n",
              "53842   13.01    13.0   13.78    0.06  ...      NaN      NaN       NaN   \n",
              "53843   13.00    13.0   13.84    0.04  ...      NaN      NaN       NaN   \n",
              "53844   13.09    13.0   14.00    0.20  ...      NaN      NaN       NaN   \n",
              "53845   13.42    13.0   14.00    0.38  ...      NaN      NaN       NaN   \n",
              "53846   13.41    13.0   14.00    0.37  ...      NaN      NaN       NaN   \n",
              "\n",
              "       Wa_c_min  Wa_c_max  Wa_c_std  Na_c_avg  Na_c_min  Na_c_max  Na_c_std  \n",
              "0           NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
              "1           NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
              "2           NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
              "3           NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
              "4           NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
              "...         ...       ...       ...       ...       ...       ...       ...  \n",
              "53842       NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
              "53843       NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
              "53844       NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
              "53845       NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
              "53846       NaN       NaN       NaN       NaN       NaN       NaN       NaN  \n",
              "\n",
              "[53847 rows x 138 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6aefa37a-7965-4f1e-9fa8-705bdcbc10a9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Wind_turbine_name</th>\n",
              "      <th>Date_time</th>\n",
              "      <th>Ba_avg</th>\n",
              "      <th>Ba_min</th>\n",
              "      <th>Ba_max</th>\n",
              "      <th>Ba_std</th>\n",
              "      <th>Rt_avg</th>\n",
              "      <th>Rt_min</th>\n",
              "      <th>Rt_max</th>\n",
              "      <th>Rt_std</th>\n",
              "      <th>...</th>\n",
              "      <th>Pas_max</th>\n",
              "      <th>Pas_std</th>\n",
              "      <th>Wa_c_avg</th>\n",
              "      <th>Wa_c_min</th>\n",
              "      <th>Wa_c_max</th>\n",
              "      <th>Wa_c_std</th>\n",
              "      <th>Na_c_avg</th>\n",
              "      <th>Na_c_min</th>\n",
              "      <th>Na_c_max</th>\n",
              "      <th>Na_c_std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>R80711</td>\n",
              "      <td>1/1/2017 0:00</td>\n",
              "      <td>-0.99</td>\n",
              "      <td>-0.99</td>\n",
              "      <td>-0.90</td>\n",
              "      <td>0.00</td>\n",
              "      <td>12.00</td>\n",
              "      <td>12.0</td>\n",
              "      <td>12.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>R80711</td>\n",
              "      <td>1/1/2017 0:10</td>\n",
              "      <td>-0.99</td>\n",
              "      <td>-0.99</td>\n",
              "      <td>-0.99</td>\n",
              "      <td>0.00</td>\n",
              "      <td>12.00</td>\n",
              "      <td>12.0</td>\n",
              "      <td>12.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>R80711</td>\n",
              "      <td>1/1/2017 0:20</td>\n",
              "      <td>-0.99</td>\n",
              "      <td>-0.99</td>\n",
              "      <td>-0.70</td>\n",
              "      <td>0.01</td>\n",
              "      <td>12.00</td>\n",
              "      <td>12.0</td>\n",
              "      <td>12.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>R80711</td>\n",
              "      <td>1/1/2017 0:30</td>\n",
              "      <td>-0.99</td>\n",
              "      <td>-0.99</td>\n",
              "      <td>-0.99</td>\n",
              "      <td>0.00</td>\n",
              "      <td>12.00</td>\n",
              "      <td>12.0</td>\n",
              "      <td>12.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>R80711</td>\n",
              "      <td>1/1/2017 0:40</td>\n",
              "      <td>-0.99</td>\n",
              "      <td>-0.99</td>\n",
              "      <td>-0.99</td>\n",
              "      <td>0.00</td>\n",
              "      <td>12.00</td>\n",
              "      <td>12.0</td>\n",
              "      <td>12.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53842</th>\n",
              "      <td>R80711</td>\n",
              "      <td>1/12/2018 23:20</td>\n",
              "      <td>-0.83</td>\n",
              "      <td>-0.99</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.32</td>\n",
              "      <td>13.01</td>\n",
              "      <td>13.0</td>\n",
              "      <td>13.78</td>\n",
              "      <td>0.06</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53843</th>\n",
              "      <td>R80711</td>\n",
              "      <td>1/12/2018 23:30</td>\n",
              "      <td>-0.15</td>\n",
              "      <td>-0.49</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.23</td>\n",
              "      <td>13.00</td>\n",
              "      <td>13.0</td>\n",
              "      <td>13.84</td>\n",
              "      <td>0.04</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53844</th>\n",
              "      <td>R80711</td>\n",
              "      <td>1/12/2018 23:40</td>\n",
              "      <td>0.03</td>\n",
              "      <td>-0.49</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.26</td>\n",
              "      <td>13.09</td>\n",
              "      <td>13.0</td>\n",
              "      <td>14.00</td>\n",
              "      <td>0.20</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53845</th>\n",
              "      <td>R80711</td>\n",
              "      <td>1/12/2018 23:50</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.10</td>\n",
              "      <td>13.42</td>\n",
              "      <td>13.0</td>\n",
              "      <td>14.00</td>\n",
              "      <td>0.38</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53846</th>\n",
              "      <td>R80711</td>\n",
              "      <td>1/13/2018 0:00</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-0.49</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.36</td>\n",
              "      <td>13.41</td>\n",
              "      <td>13.0</td>\n",
              "      <td>14.00</td>\n",
              "      <td>0.37</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>53847 rows × 138 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6aefa37a-7965-4f1e-9fa8-705bdcbc10a9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6aefa37a-7965-4f1e-9fa8-705bdcbc10a9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6aefa37a-7965-4f1e-9fa8-705bdcbc10a9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-98f4274f-3e11-4d2d-a60a-6352808ce139\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-98f4274f-3e11-4d2d-a60a-6352808ce139')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-98f4274f-3e11-4d2d-a60a-6352808ce139 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_14d43c19-e795-4121-855f-3a4866357068\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_14d43c19-e795-4121-855f-3a4866357068 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "aaHdfN3lHMzb"
      },
      "outputs": [],
      "source": [
        "df['Date'] = pd.to_datetime(df['Date_time'])\n",
        "df['Year'] = df['Date'].dt.year\n",
        "df['Month'] = df['Date'].dt.month\n",
        "new_data=df[['Month','Year','Date','P_avg']]\n",
        "new_data=new_data[new_data.Year == 2017]\n",
        "\n",
        "cap=max(new_data['P_avg'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "LYzmQc2mHQX2"
      },
      "outputs": [],
      "source": [
        "i=[1,2] #for fold-1\n",
        "look_back=6\n",
        "data_partition=0.5257331291956189"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "XA7K7V1QHU2U"
      },
      "outputs": [],
      "source": [
        "CUDA_VISIBLE_DEVICES=\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "obL82JoyHg57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4eb03442-48ae-47b0-fe69-4aca09cad715"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAPE: 4.177064091203618\n",
            "RMSE: 130.61584545659562\n",
            "MAE: 85.65821372843024\n"
          ]
        }
      ],
      "source": [
        "svr_model(new_data,i,look_back,data_partition,cap)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ROV03AslfjLh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3aaa4454-2446-4511-e8a7-3d63874e358e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "MAPE: 4.8182178\n",
            "RMSE: 151.92779432184224\n",
            "MAE: 98.80622100830078\n"
          ]
        }
      ],
      "source": [
        "ann_model(new_data,i,look_back,data_partition,cap)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "77RnYXO2q4NI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f14e6a2e-858e-4c7b-f218-1aaa57e4f190"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAPE: 3.994839370142407\n",
            "RMSE: 134.50734290614565\n",
            "MAE: 81.92136800079696\n"
          ]
        }
      ],
      "source": [
        "rf_model(new_data,i,look_back,data_partition,cap)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install EMD-signal"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bCLTlNkv-gq",
        "outputId": "b1cf8131-dec9-4cc5-9fde-e01ad589e4aa"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: EMD-signal in /usr/local/lib/python3.11/dist-packages (1.6.4)\n",
            "Requirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.11/dist-packages (from EMD-signal) (2.0.2)\n",
            "Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.11/dist-packages (from EMD-signal) (1.14.1)\n",
            "Requirement already satisfied: pathos>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from EMD-signal) (0.3.3)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from EMD-signal) (4.67.1)\n",
            "Requirement already satisfied: ppft>=1.7.6.9 in /usr/local/lib/python3.11/dist-packages (from pathos>=0.2.1->EMD-signal) (1.7.6.9)\n",
            "Requirement already satisfied: dill>=0.3.9 in /usr/local/lib/python3.11/dist-packages (from pathos>=0.2.1->EMD-signal) (0.3.9)\n",
            "Requirement already satisfied: pox>=0.3.5 in /usr/local/lib/python3.11/dist-packages (from pathos>=0.2.1->EMD-signal) (0.3.5)\n",
            "Requirement already satisfied: multiprocess>=0.70.17 in /usr/local/lib/python3.11/dist-packages (from pathos>=0.2.1->EMD-signal) (0.70.17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PyEMD import CEEMDAN"
      ],
      "metadata": {
        "id": "nFjafl9gwC56"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from math import sqrt\n",
        "import ewtpy\n",
        "from PyEMD import CEEMDAN\n",
        "\n",
        "# Proposed Hybrid CEEMDAN-EWT LSTM Model\n",
        "def proposed_method(new_data, i, look_back, data_partition, cap):\n",
        "    data1 = new_data.loc[new_data['Month'].isin(i)].reset_index(drop=True).dropna()\n",
        "    datas = data1['P_avg']\n",
        "\n",
        "    # Ensure `datas` is 1D before reshaping\n",
        "    print(\"Original shape of datas:\", datas.shape)\n",
        "    datasets = datas.values.reshape(-1, 1)  # Reshape to (N, 1)\n",
        "\n",
        "    # CEEMDAN Decomposition\n",
        "    emd = CEEMDAN(epsilon=0.05)\n",
        "    emd.noise_seed(12345)\n",
        "    IMFs = emd(datasets.flatten())\n",
        "    ceemdan1 = pd.DataFrame(IMFs).T\n",
        "    imf1 = ceemdan1.iloc[:, 0]\n",
        "\n",
        "    # EWT Decomposition\n",
        "    ewt, _, _ = ewtpy.EWT1D(imf1, N=3)\n",
        "    df_ewt = pd.DataFrame(ewt)\n",
        "\n",
        "    # Drop unwanted component, ensuring shape consistency\n",
        "    if df_ewt.shape[1] > 2:\n",
        "        df_ewt.drop(columns=[2], inplace=True)\n",
        "\n",
        "    denoised = df_ewt.sum(axis=1)\n",
        "    ceemdan_without_imf1 = ceemdan1.iloc[:, 1:]\n",
        "    new_ceemdan = pd.concat([denoised, ceemdan_without_imf1], axis=1)\n",
        "\n",
        "    # **Ensure 2D shape before converting to DataFrame**\n",
        "    print(f\"new_ceemdan shape before pd.DataFrame(): {new_ceemdan.shape}\")\n",
        "    if len(new_ceemdan.shape) == 3:\n",
        "        print(f\"Fixing new_ceemdan shape from {new_ceemdan.shape} to 2D\")\n",
        "        new_ceemdan = new_ceemdan.reshape(new_ceemdan.shape[0], -1)\n",
        "    print(f\"new_ceemdan shape after reshape: {new_ceemdan.shape}\")\n",
        "\n",
        "    pred_test, test_ori, pred_train, train_ori = [], [], [], []\n",
        "    epoch, batch_size, lr = 100, 64, 0.001\n",
        "\n",
        "    # Iterate over each IMF for LSTM Training\n",
        "    for col in new_ceemdan:\n",
        "        dataset = new_ceemdan[[col]].values\n",
        "\n",
        "        # **Ensure dataset is 2D**\n",
        "        print(f\"Dataset shape before reshape: {dataset.shape}\")\n",
        "        if len(dataset.shape) == 3:\n",
        "            print(f\"Fixing dataset shape from {dataset.shape} to 2D\")\n",
        "            dataset = dataset.reshape(dataset.shape[0], -1)\n",
        "        print(f\"Dataset shape after reshape: {dataset.shape}\")\n",
        "\n",
        "        train_size = int(len(dataset) * data_partition)\n",
        "        train, test = dataset[:train_size], dataset[train_size:]\n",
        "\n",
        "        trainX, trainY = create_dataset(train, look_back)\n",
        "        testX, testY = create_dataset(test, look_back)\n",
        "\n",
        "        # Debugging Shape\n",
        "        print(f\"Feature: {col}, TrainX Shape: {trainX.shape}, TrainY Shape: {trainY.shape}\")\n",
        "\n",
        "        sc_X, sc_y = StandardScaler(), StandardScaler()\n",
        "\n",
        "        # Ensure StandardScaler gets 2D input\n",
        "        X_train = sc_X.fit_transform(trainX.reshape(trainX.shape[0], -1))\n",
        "        y_train = sc_y.fit_transform(trainY.reshape(-1, 1)).ravel()\n",
        "        X_test = sc_X.transform(testX.reshape(testX.shape[0], -1))\n",
        "        y_test = sc_y.fit_transform(testY.reshape(-1, 1)).ravel()\n",
        "\n",
        "        # Ensure LSTM input is 3D\n",
        "        trainX = X_train.reshape(X_train.shape[0], look_back, -1)\n",
        "        testX = X_test.reshape(X_test.shape[0], look_back, -1)\n",
        "\n",
        "        print(\"Final TrainX shape for LSTM:\", trainX.shape)  # Should be (samples, timesteps, features)\n",
        "        print(\"Final TestX shape for LSTM:\", testX.shape)\n",
        "\n",
        "        # Set random seed for reproducibility\n",
        "        np.random.seed(1234)\n",
        "        tf.random.set_seed(1234)\n",
        "        os.environ['PYTHONHASHSEED'] = '0'\n",
        "\n",
        "        # Build and train LSTM model\n",
        "        model = Sequential()\n",
        "        model.add(tf.keras.layers.Input(shape=(trainX.shape[1], trainX.shape[2])))\n",
        "        model.add(LSTM(units=128))\n",
        "        model.add(Dense(1))\n",
        "\n",
        "        model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(learning_rate=lr))\n",
        "        model.fit(trainX, y_train, epochs=epoch, batch_size=batch_size, verbose=0)\n",
        "\n",
        "        # Predictions\n",
        "        y_pred_train = model.predict(trainX).ravel()\n",
        "        y_pred_test = model.predict(testX).ravel()\n",
        "\n",
        "        # Inverse transform predictions\n",
        "        y_pred_train1 = sc_y.inverse_transform(y_pred_train.reshape(-1, 1))\n",
        "        y_pred_test1 = sc_y.inverse_transform(y_pred_test.reshape(-1, 1))\n",
        "        y_train = sc_y.inverse_transform(y_train.reshape(-1, 1))\n",
        "        y_test = sc_y.inverse_transform(y_test.reshape(-1, 1))\n",
        "\n",
        "        # **Ensure predictions are 2D before appending**\n",
        "        y_pred_test1 = np.array(y_pred_test1)\n",
        "        y_pred_train1 = np.array(y_pred_train1)\n",
        "        y_test = np.array(y_test)\n",
        "        y_train = np.array(y_train)\n",
        "\n",
        "        pred_test.append(y_pred_test1)\n",
        "        test_ori.append(y_test)\n",
        "        pred_train.append(y_pred_train1)\n",
        "        train_ori.append(y_train)\n",
        "\n",
        "    # **Final Fix: Use Mean Instead of Sum for IMFs**\n",
        "    print(f\"Final pred_test shape before DataFrame: {np.array(pred_test).shape}\")\n",
        "    print(f\"Final pred_train shape before DataFrame: {np.array(pred_train).shape}\")\n",
        "\n",
        "    pred_test = np.array(pred_test).reshape(len(pred_test), -1)  # Convert to (IMFs, Samples)\n",
        "    pred_train = np.array(pred_train).reshape(len(pred_train), -1)  # Convert to (IMFs, Samples)\n",
        "    test_ori = np.array(test_ori).reshape(len(test_ori), -1)\n",
        "\n",
        "    # Take Mean Instead of Sum Over IMFs\n",
        "    result_pred_test = pd.DataFrame(pred_test.mean(axis=0))  # Fix: Using mean\n",
        "    result_pred_train = pd.DataFrame(pred_train.mean(axis=0))\n",
        "    y_test = pd.DataFrame(test_ori.mean(axis=0))\n",
        "\n",
        "    print(f\"Final result_pred_test shape: {result_pred_test.shape}\")\n",
        "    print(f\"Final result_pred_train shape: {result_pred_train.shape}\")\n",
        "    print(f\"Final y_test shape: {y_test.shape}\")\n",
        "\n",
        "    # Error Metrics Calculation\n",
        "    mape = np.mean((np.abs(y_test - result_pred_test)) / cap) * 100\n",
        "    rmse = sqrt(mean_squared_error(y_test, result_pred_test))\n",
        "    mae = mean_absolute_error(y_test, result_pred_test)\n",
        "\n",
        "    print('MAPE:', mape)\n",
        "    print('RMSE:', rmse)\n",
        "    print('MAE:', mae)\n"
      ],
      "metadata": {
        "id": "QD_CudRXN328"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d0bc25c-0d9e-4870-f920-8b7161eddb98",
        "id": "gDgBEAjCmgiR"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original shape of datas: (8491,)\n",
            "new_ceemdan shape before pd.DataFrame(): (8491, 11)\n",
            "new_ceemdan shape after reshape: (8491, 11)\n",
            "Dataset shape before reshape: (8491, 1)\n",
            "Dataset shape after reshape: (8491, 1)\n",
            "Feature: 0, TrainX Shape: (4457, 6), TrainY Shape: (4457,)\n",
            "Final TrainX shape for LSTM: (4457, 6, 1)\n",
            "Final TestX shape for LSTM: (4020, 6, 1)\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "Dataset shape before reshape: (8491, 1)\n",
            "Dataset shape after reshape: (8491, 1)\n",
            "Feature: 1, TrainX Shape: (4457, 6), TrainY Shape: (4457,)\n",
            "Final TrainX shape for LSTM: (4457, 6, 1)\n",
            "Final TestX shape for LSTM: (4020, 6, 1)\n"
          ]
        }
      ],
      "source": [
        "proposed_method(new_data,i,look_back,data_partition,cap)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}